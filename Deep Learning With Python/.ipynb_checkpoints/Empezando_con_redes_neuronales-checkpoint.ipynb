{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anatomía de una red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las redes neuronales están formadas por **4** componentes:\n",
    "- **Capas**, que se combinan formando una red (o modelo)\n",
    "- Los **datos de entrada** y los correspondientes **objetivos**\n",
    "- La **función de pérdida** (función  objetivo)\n",
    "- El **optimizador, que determina cómo aprende la red**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Anatomia de la red](anatomia_red.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capas: los ladrillos del deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un módulo **procesador de datos** que recibe una entrada de uno o más tensores y da una salida de uno o más tensores. Algunas capas no tienen estado, pero la mayoría lo tiene. Este estado son los **pesos** de la red, uno o más tensores que contienen el **conocimiento** de la red.  \n",
    "Cada tipo de capas son mejores o peores para algunos tipos de tensores.\n",
    "\n",
    "Crear un modelo en deep learning es básicamente encajar **capas compatibles**.\n",
    "La noción de compatibilidad la usamos ya que las capas solo aceptan tensores de una cierta forma, teniendo que encajar la salida de la anterior capa con la entrada de la siguiente. Mostramos esto con un ejemplo usando Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear una capa que solo admita tensores 2D en los que su primera dimensión es 784, y devuelve un tensor en el que su primera dimensión ha sido transformada a 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "layer = layers.Dense(32, input_shape=(784,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La compatibilidad entre capas usando Keras no es ningún problema ya que **encajan automáticamente**, como vemos en el siguiente ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"opencl_amd_ellesmere.0\"\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, input_shape=(784,)))\n",
    "model.add(layers.Dense(32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí vemos que no surge ningún tipo de fallo, ya que la segunda capa se adapta automáticamente a la salida de la primera (vemos que no le hemos pasado el argumento para la forma del input), es decir, un tensor en el que la primera dimensión es 32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos: redes de capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un modelo de deep-learning es un grafo de capas directo y acíclico.  \n",
    "El tipo más típico de modelo es una **pila lineal de capas**, que tiene una entrada y una sola salida. Algunos ejemplos más son las **redes de dos ramas**, las **redes multi-cabeza** y los **bloques de inicio**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La topología de una red define un **espacio de hipótesis**.  \n",
    "Eligiendo la topología de la red, reducimos nuestro **espacio de posibilidades** (espacio de hipótesis) a una serie específica de operaciones de tensores que mapean los datos de entrada con los de salida.  \n",
    "Elegir la arquitectura de la red es un paso muy importante en la construcción de la propia red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de pérdida y optimizadores: las claves para configurar el proceso de aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Función de pérdida** (función objetivo): la cantidad que va a ser minimizada durante el entrenamiento. Representa una medida de éxito para la tarea que estamos ejecutando.\n",
    "- **Optimizador**: Determina cómo la red va a ser modificada, basándose en la función objetivo. Implementa alguna variante del descenso por el gradiente estocástico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una red tiene **tantas funciones objetivos como salidas** tenga, pero el proceso del descenso por el gradiente se basa en **un solo escalar**. Este escalar es la **media** de los valores de todas las funciones objetivo.\n",
    "\n",
    "Elegir las funciones objetivos es un paso muy importante a la hora de definir nuestra red, ya que la red minimizará esa función lo máximo posible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tyk2]",
   "language": "python",
   "name": "conda-env-.conda-tyk2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
