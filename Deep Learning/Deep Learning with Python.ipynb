{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumen del libro Deep Learning with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## [Tensores](#Tensores)\n",
    " \n",
    " #### [Escalar](#Escalar)\n",
    " #### [Vector](#Vector)\n",
    " #### [Matriz](#Matriz)\n",
    " #### [Tensor 3-dimensional](#Tensor-3-dimensional)\n",
    " #### [Tensor n-dimensional](#Tensor-n-dimensional)\n",
    " \n",
    " ### [Manipulando tensores](#Manipulando-tensores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las estructuras basicas de datos en Deep Learning son los tensores\n",
    "que son basicamente arrays n-dimensionales, por ejemplo una matriz\n",
    "es un tensor 2-dimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: 27\n",
      "Dimension: 0\n"
     ]
    }
   ],
   "source": [
    "# Vamos a crear un escalar (tensor 0-dimensional) en numpy:\n",
    "\n",
    "escalar = np.array(27)\n",
    "print(\"Tensor: \" + str(escalar)) # Nos muestra el escalar que acabamos de crear\n",
    "print(\"Dimension: \" + str(escalar.ndim)) # Nos muestra las dimensiones (el rango o los ejes) del tensor que hemos creado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: [1 2 3 4]\n",
      "Dimension: 1\n"
     ]
    }
   ],
   "source": [
    "# Vamos a crear un vector (tensor 1-dimensional) en numpy:\n",
    "\n",
    "vector = np.array([1,2,3,4]) # Creamos un vector 4-dimensional\n",
    "print(\"Tensor: \" + str(vector))\n",
    "print(\"Dimension: \" + str(vector.ndim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      "\n",
      " [[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n",
      "\n",
      " Dimension: 2\n"
     ]
    }
   ],
   "source": [
    "# Vamos a crear una matriz (tensor 2-dimensional) en numpy:\n",
    "\n",
    "matriz = np.array([[1,2,3,4],\n",
    "                  [5,6,7,8],\n",
    "                  [9,10,11,12]])\n",
    "print(\"Tensor: \\n\\n \" + str(matriz))\n",
    "print(\"\\n Dimension: \" + str(matriz.ndim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor 3-dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: \n",
      "\n",
      " [[[ 1  1  2 34  0]\n",
      "  [ 6  2  3 35  1]\n",
      "  [ 7  3  4 36  2]]\n",
      "\n",
      " [[ 2  1  2 34  0]\n",
      "  [ 6  2  3 35  1]\n",
      "  [ 7  3  4 36  2]]\n",
      "\n",
      " [[ 3  1  2 34  0]\n",
      "  [ 6  2  3 35  1]\n",
      "  [ 7  3  4 36  2]]]\n",
      "\n",
      " Dimension: 3\n"
     ]
    }
   ],
   "source": [
    "#Vamos a crear un tensor 3-dimensional en numpy:\n",
    "\n",
    "tensor3d = np.array([  [[1, 1, 2, 34, 0],\n",
    "                       [6, 2, 3, 35, 1],\n",
    "                       [7, 3, 4, 36, 2]],\n",
    "              \n",
    "                       [[2, 1, 2, 34, 0],\n",
    "                       [6, 2, 3, 35, 1],\n",
    "                       [7, 3, 4, 36, 2]],\n",
    "                \n",
    "                       [[3, 1, 2, 34, 0],\n",
    "                       [6, 2, 3, 35, 1],\n",
    "                       [7, 3, 4, 36, 2]]   ])\n",
    "\n",
    "print(\"Tensor: \\n\\n \" + str(tensor3d))\n",
    "print(\"\\n Dimension: \" + str(tensor3d.ndim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensores n-dimensionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede que nos hayamos dado cuenta de un patron. Aumentar de dimension un tensor no es mas\n",
    "que meter varios tensores de la dimension anterior en un array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulando tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para **crear** tensores es como hemos visto arriba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "tensor = np.array([1,2])\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver la **forma** que tiene un tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "forma = tensor3d.shape\n",
    "print(forma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver el **tipo** de un tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    }
   ],
   "source": [
    "tipo = tensor3d.dtype\n",
    "print(tipo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un slicing normal y corriente, pero hay que tener en cuenta la n-dimensionalidad del tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "tensor3d_slice1: \n",
      "\n",
      "[[[1 1]]]\n",
      "---------------------\n",
      "tensor3d_slice2: \n",
      "\n",
      "[[[1 1]\n",
      "  [6 2]]\n",
      "\n",
      " [[2 1]\n",
      "  [6 2]]]\n",
      "---------------------\n",
      "tensor3d_slice3: \n",
      "\n",
      "[[[1 1]]\n",
      "\n",
      " [[2 1]]\n",
      "\n",
      " [[3 1]]]\n"
     ]
    }
   ],
   "source": [
    "tensor3d_slice1 = tensor3d[0:1,0:1,0:2] # De la primera matriz coge la primera fila, los dos primeros elementos.\n",
    "tensor3d_slice2 = tensor3d[0:2,0:2,0:2] # De las 2 primeras matrices coge las 2 primeras filas, y de estas los dos primeros elementos.\n",
    "tensor3d_slice3 = tensor3d[0:3,0:1,0:2] # De las 3 primeras matrices coge la primera fila, los dos primeros elementos.\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"tensor3d_slice1: \\n\")\n",
    "print(tensor3d_slice1)\n",
    "print(\"---------------------\")\n",
    "print(\"tensor3d_slice2: \\n\")\n",
    "print(tensor3d_slice2)\n",
    "print(\"---------------------\")\n",
    "print(\"tensor3d_slice3: \\n\")\n",
    "print(tensor3d_slice3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los indices del slicing se van seleccionando de fuera hacia dentro.\n",
    "en el ejemplo ` tensor3d[0:3,0:1,0:2] ` hemos seleccionado las 3 primeras matrices,\n",
    "de estas tres matrices hemos cogido de cada una la primera fila, y de cada una de las filas que\n",
    "hemos cogido solo nos quedamos con los 2 primeros elementos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Deep Learning consideramos el primer indice (el primer eje) como el **eje de los ejemplos**\n",
    ",ya que es el indice del conjunto mas exterior que engloba todos los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lotes de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalmente en Deep Learning los ejemplos se usan por **lotes** (batchs en ingles), es decir,\n",
    "separan todos los ejemplos que tenemos en dos o mas lotes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensores en el mundo real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectores de datos ->** tensores 2-d de la forma (ejemplos, caracteristicas)\n",
    "\n",
    "**Series temporales ->** tensores 3-d de la forma (ejemplos, tiempo, caracteristicas).\n",
    "\n",
    "**Imagenes ->** tensores 4-d de la forma (ejemplos, altura, anchura, canales) o de la forma (ejemplos, canales, altura, anchura)\n",
    "\n",
    "**Videos ->** tensores 5-d de la forma (ejemplos, frames, altura, anchura, canales) o de la forma (ejemplos, frames, canales, altura, anchura)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones con tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operacion ReLu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_relu(x):\n",
    "    \n",
    "    assert len(x.shape)==2 # Nos aseguramos antes de empezar el programa que\n",
    "                           # lo que le pasamos es un tensor 2-d\n",
    "    \n",
    "    x = x.copy() # Evitamos modificar el tensor original\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i,j] = max(x[i,j],0)\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suma de tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add(x,y):\n",
    "    \n",
    "    assert len(x.shape)==2 # Nos aseguramos de que los dos elementos que\n",
    "    assert len(y.shape)==2 # vamos a sumar son tensores 2-d\n",
    "    \n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i,j] += y[i,j]\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabiendo como es la suma podemos implementar facilmente la resta, multiplicacion y la division. Solo hay que cambiar que operacion hacemos con los elementos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suma de tensores de distinta dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add_matrix_and_vector(x, y):\n",
    "    \n",
    "    assert len(x.shape) == 2 # Una matriz\n",
    "    assert len(y.shape) == 1 # Un vector\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    \n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            \n",
    "            x[i, j] += y[j] # A todos los elementos de la misma columna\n",
    "                            # les vamos sumando cada elemento correspondiente\n",
    "                            # del vector\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producto escalar entre vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_vector_dot(x, y):\n",
    "    \n",
    "    assert len(x.shape) == 1\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "\n",
    "    z = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "        \n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producto escalar entre matriz y vector:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada elemento de z es el producto escalar entre cada fila de la matriz y el vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    \n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    \n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] += x[i, j] * y[j]\n",
    "            \n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producto escalar entre matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_dot(x, y):\n",
    "    \n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 2\n",
    "    assert x.shape[1] == y.shape[0] # Solo se puede hacer si la primera\n",
    "                                    # matriz tiene las mismas columnas\n",
    "                                    # como filas tiene la segunda\n",
    "            \n",
    "    z = np.zeros((x.shape[0], y.shape[1]))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            row_x = x[i, :]\n",
    "            column_y = y[:, j]\n",
    "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo esto se hace mucho mas simple con numpy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suma de tensores en numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 7 9]\n"
     ]
    }
   ],
   "source": [
    "xs,ys = np.array([1,2,3]),np.array([4,5,6])\n",
    "\n",
    "suma = xs + ys # Da igual si son de distinta dimension\n",
    "print(suma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operacion ReLu en numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0]\n"
     ]
    }
   ],
   "source": [
    "xr = np.array([1,-1,0])\n",
    "\n",
    "relu = np.maximum(xr, 0)\n",
    "print(relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producto escalar en numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "xe,ye = np.array([1,2,3]),np.array([4,5,6])\n",
    "\n",
    "prod_esc = np.dot(xe, ye)\n",
    "print(prod_esc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ejemplo de forma](producto_escalar_matrices.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remodelado de tensores en numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin remodelar: \n",
      "[[0. 1.]\n",
      " [2. 3.]\n",
      " [4. 5.]]\n",
      "\n",
      " Remodelado: \n",
      "[[0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [5.]]\n"
     ]
    }
   ],
   "source": [
    "xre = np.array([[0., 1.],\n",
    "                [2., 3.],\n",
    "                [4., 5.]])\n",
    "print(\"Sin remodelar: \\n\" + str(xre))\n",
    "\n",
    "remodelado = xre.reshape((6,1))\n",
    "print(\"\\n Remodelado: \\n\" + str(remodelado))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpuesta de una matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz: \n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n",
      "\n",
      " Transpuesta: \n",
      "[[ 1  5  9]\n",
      " [ 2  6 10]\n",
      " [ 3  7 11]\n",
      " [ 4  8 12]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matriz: \\n\" + str(matriz))\n",
    "\n",
    "transpuesta = matriz.transpose()\n",
    "print(\"\\n Transpuesta: \\n\" + str(transpuesta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El motor de las Redes Neuronales:  optimizacion basada en gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la base del Machine Learning esta el *bucle de entrenamiento*:\n",
    "\n",
    "1- Coge un lote de ejemplos que seran entrenamiento y otro para targets.  \n",
    "\n",
    "2- Ejecuta la red sobre entrenamiento para obtener predicciones sobre los targets.  \n",
    "\n",
    "3- Calcula la diferencia entre lo que deberia haber predecido y lo que ha predecido.  \n",
    "\n",
    "4- Actualiza los pesos de la red para minimizar la diferencia.\n",
    "\n",
    "Este bucle es basicamente lo que permite a nuestro modelo aprender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos estos pasos son relativamente sencillos, excepto el cuarto, para el que usaremos el **gradiente**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero tenemos que definir el concepto de **derivada**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Derivada de f en p](derivada_de_f_en_p.png)\n",
    "Derivada de f en p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La derivada nos inidica **como varia** y en funcion de x.\n",
    "Para que una funcion sea derivable tiene que ser **continua** y **suave**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradiente: derivada de una operacion de tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es basicamente la derivada de una funcion en un tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gradiente de un tensor](gradiente_de_un_tensor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos un numero que nos indique cuanto nos movemos en en el gradiente.\n",
    "A este numero normalmente se le llama ***Learning Rate***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descenso por el gradiente estocastico (aleatorio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mini-batch stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Coge un lote de los ejemplos de entrenamiento x y sus correspondientes targets.  \n",
    "\n",
    "2- Ejecuta la red sobre x para obtener *y_preds*.  \n",
    "\n",
    "3- Calcula la diferencia entre lo predecido y lo que deberiamos haber predecido.  \n",
    "\n",
    "4- Calcula el gradiente de esa diferencia, considerando los parametros de la red.  \n",
    "\n",
    "5- Modifica los parametros de la red en direccion opuesta al gradiente, por ejemplo `W-= step * gradient` para reducir la diferencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si cogiesemos un elemento solo por cada iteracion, estariamos hablando de ***true stochastic gradient descent***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si cogiesemos todos los datos en cada iteracion, hablariamos de ***batch stochastic gradient descent***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gradiente en 2D](gradiente_2d.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
