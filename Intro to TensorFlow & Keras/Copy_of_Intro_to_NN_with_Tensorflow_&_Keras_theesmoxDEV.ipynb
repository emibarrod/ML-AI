{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Intro to NN with Tensorflow & Keras - theesmoxDEV",
      "provenance": [],
      "collapsed_sections": [
        "VxvLcrUEhiyy",
        "pd0CjDH2Q6mr",
        "gv9pUIS6dtsT",
        "ceenrgwUdHjn",
        "Sn0s_ZtFmfgT",
        "Lpo3COr5kGSs",
        "gCjZJ_2yTWnY",
        "pAaisLceVybq",
        "E0uOoaP9u0eC",
        "InXWGlPFQXpX"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG46YhAXvREp",
        "colab_type": "text"
      },
      "source": [
        "# ***INDEX***\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq5xMNQg00bp",
        "colab_type": "text"
      },
      "source": [
        "## 1. **[Introducing Neural Networks](#Introducing-Neural-Networks)**\n",
        "### 1.1. [Perceptron](#Perceptron)\n",
        "### 1.2. [Neural Network](#Neural-Network)\n",
        "### 1.3. [How does learning takes place?](#How-does-learning-take-place?)\n",
        "---\n",
        "## 2. **[Tensorflow](#TensorFlow)**\n",
        "### 2.1. [Constants](#Constants-(Tensors))\n",
        "### 2.2. [Tensor operations](#Tensor-operations)\n",
        "---\n",
        "## 3. **[Keras](#Keras)**\n",
        "### 3.1. [Building Neural Networks](#Building-Neural-Networks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75KYvTRcg-Uu",
        "colab_type": "text"
      },
      "source": [
        "In this intro, I will not be explaining lot of maths, I will just show the formulas and some stuff, becaus I just want this to be an overview."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxvLcrUEhiyy",
        "colab_type": "text"
      },
      "source": [
        "# **Introducing Neural Networks**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIIxvJZI7rmb",
        "colab_type": "text"
      },
      "source": [
        "Before we introduce NN, we need to understand what is a perceptron."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmDU0IEXc1GF",
        "colab_type": "text"
      },
      "source": [
        "## **Perceptron**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40MYiM3zaBSC",
        "colab_type": "text"
      },
      "source": [
        "It is a \"neuron\".  \n",
        "Each unit that the neural network has is a perceptron:\n",
        "\n",
        "![perceptron image](https://github.com/theesmoxDEV/ML-AI/blob/master/Intro%20to%20TensorFlow%20%26%20Keras/Perceptron_diagram.png?raw=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypplqpBJdGuW",
        "colab_type": "text"
      },
      "source": [
        "It has the inputs (the training data), weights associated to those inputs, a bias, a sum, an activation function and an output (our prediction).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KvVdwcAdXDE",
        "colab_type": "text"
      },
      "source": [
        "Mathematically, we can explain this diagram like this:\n",
        "\n",
        "$y = \\varphi(x_0w_0 + \\sum_{i=1}^{n} x_iw_i)$  \n",
        "\n",
        "---\n",
        "\n",
        "this is the same as  \n",
        "\n",
        "$y = \\varphi(x_0w_0 + X^{T}W)$  \n",
        " \n",
        " ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EowCNn8kdduY",
        "colab_type": "text"
      },
      "source": [
        "Where:\n",
        "\n",
        "* $X$ are the inputs:\n",
        "$\n",
        "\\left(\\begin{array}{cc} \n",
        "x_i\\\\\n",
        "...\\\\\n",
        "x_n\n",
        "\\end{array}\\right)\n",
        "$\n",
        "---\n",
        "* $W$ are the weights:\n",
        "$\n",
        "\\left(\\begin{array}{cc} \n",
        "w_i\\\\\n",
        "...\\\\\n",
        "w_n\n",
        "\\end{array}\\right)\n",
        "$\n",
        "---\n",
        "* $\\varphi$ is the activation function: there are lots of different functions, the most usual functions are\n",
        "\n",
        "![usual functions image](https://github.com/theesmoxDEV/ML-AI/blob/master/Intro%20to%20TensorFlow%20%26%20Keras/usual_activation_functions.png?raw=1)\n",
        "\n",
        "---\n",
        "* $x_0w_0$ is the bias: Usually $x_0=-1$ and $w_0=1$, but it could be $x_0=1$ and $w_0=-1$ too.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd0CjDH2Q6mr",
        "colab_type": "text"
      },
      "source": [
        "## **Neural Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbmMRXj-RNSy",
        "colab_type": "text"
      },
      "source": [
        "It is like a brain.  \n",
        "A simple neural network (NN) has an input layer, a hidden layer and an output layer.\n",
        "\n",
        "In this image we se a fully connected NN, with 4 input units, 5 hidden units and 1 output unit:\n",
        "\n",
        "![neural network image](https://github.com/theesmoxDEV/ML-AI/blob/master/Intro%20to%20TensorFlow%20%26%20Keras/neural_network.png?raw=1)\n",
        "\n",
        "Each unit is a perceptron with its own weights.\n",
        "As we see, as in the perceptron, we have a sum and an activation function in each perceptron of each layer.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghWpM2IeiKM4",
        "colab_type": "text"
      },
      "source": [
        "I will not go too deep in this structure as that is no my objective in this intro. I just want to show an overview."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJhHZRD1eLrD",
        "colab_type": "text"
      },
      "source": [
        "## **How does learning take place?**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88r5nd2qpkHn",
        "colab_type": "text"
      },
      "source": [
        "To fully understand the learning process requires tons of math. I will try to simplify it as much as I can, to have a vision of how can it be."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSo8Ghs2qO7f",
        "colab_type": "text"
      },
      "source": [
        "### **The basis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "284n21YTqRhQ",
        "colab_type": "text"
      },
      "source": [
        "Basically, the learning process consists in **updating the weights of the perceptron** (or peceptrons, if we are training a Neural Network).\n",
        "\n",
        "To train a perceptron we need **training data** and **training targets**:\n",
        "\n",
        " * **Training data:** it is the data we use to feed our perceptron. The model we create tries to \"fit\" to this data.\n",
        " * **Training target:** it is usually included in the training data. The training target is the \"thing\" or the \"label\" we want our perceptron to predict. **It is the output we want to achieve updating the weights.**\n",
        "\n",
        "---\n",
        "\n",
        "**Example:** Trying to learn OR operation\n",
        "\n",
        "We could have the following **training data** [ [1, 1], [1, 0], [0, 1], [0, 0] ] associated with this **training targets** [ [1], [1], [1], [0] ].  \n",
        "For those who don't know what the OR operation does, **it returns 1 when there is one or more 1s**. So, associating the training data and the training targets, we have:  \n",
        "\n",
        "**[1] [1] [1]**  \n",
        "**[1] [0] [1]**  \n",
        "**[0] [1] [1]**  \n",
        "**[0] [0] [0]** , because if we have [1] [1], we expect a 1, if we have [0] [0], we expect a 0, etc.  \n",
        "\n",
        "---\n",
        "\n",
        "**Keep in mind** that we refer to both (training data and targets) as training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TnkzsYDp3ku",
        "colab_type": "text"
      },
      "source": [
        "### **Learning in perceptrons**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_7tzaD70_HU",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMVQKDnn1qNO",
        "colab_type": "text"
      },
      "source": [
        "### **Learning Neural Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct68e1wM1yiZ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cMs4bSRj3k0",
        "colab_type": "text"
      },
      "source": [
        "# **TensorFlow**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WwxQOWMkJsE",
        "colab_type": "text"
      },
      "source": [
        "As described in www.tensorflow.org:  \n",
        "\n",
        ">\"**TensorFlow is an end-to-end open source platform for machine learning.** It has a comprehensive, flexible ecosystem of tools, libraries and community resources that lets researchers push the state-of-the-art in ML and developers easily build and deploy ML powered applications.\"\n",
        "\n",
        "But basically, what bothers us right now, is that it is a **tool to manage tensors** (as all the data we feed into neural networks are tensors)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SMblwxSTcb2",
        "colab_type": "text"
      },
      "source": [
        "## **Constants (Tensors)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6NXr7Pzlcnn",
        "colab_type": "text"
      },
      "source": [
        "Tensors are n-dimensional objects.  \n",
        "A scalar is a 0-dimensional tensor, a vector is a 1-dimensional tensor, a matrix is a 2-dimensional tensor, etc. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ion2ABX_TOmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing all the necessary things\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K7xp-JWTrnX",
        "colab_type": "code",
        "outputId": "029702fd-f3d1-41b2-ae50-e3bc11b7a260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "constant_string = tf.constant(\"NAME\") # You don't have to specify the type, it\n",
        "                                      # is infered from the tensor content\n",
        "        \n",
        "constant_number = tf.constant(100, dtype=tf.int32)\n",
        "\n",
        "print(constant_string)\n",
        "print(constant_number)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'NAME', shape=(), dtype=string)\n",
            "tf.Tensor(100, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8E5jGeBVC5L",
        "colab_type": "text"
      },
      "source": [
        "As we see in the parameter \"shape\", it is empty. That means that we are using scalars. In the next example we will define multi-dimensional tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z7jsWygVTZ3",
        "colab_type": "code",
        "outputId": "34b77816-6327-4e2f-d0c1-0deacd3b3ac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "tensor_1d = tf.constant([1,2,3,4]) # vector\n",
        "\n",
        "tensor_2d = tf.constant([[1,2,3],[4,5,6]]) # matrix\n",
        "\n",
        "tensor_3d = tf.constant([[[1,2,3],[4,5,6]], [[1,2,3],[4,5,6]]]) # cube\n",
        "\n",
        "print(\"tensor_1d shape: {}\".format(tensor_1d.shape))\n",
        "print(\"----------------------------------------------\")\n",
        "print(\"tensor_2d shape: {}\".format(tensor_2d.shape))\n",
        "print(\"----------------------------------------------\")\n",
        "print(\"tensor_3d shape: {}\".format(tensor_3d.shape))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor_1d shape: (4,)\n",
            "----------------------------------------------\n",
            "tensor_2d shape: (2, 3)\n",
            "----------------------------------------------\n",
            "tensor_3d shape: (2, 2, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMw0GyaMcYr6",
        "colab_type": "text"
      },
      "source": [
        "Take in count that we have used ```tf.shape``` to check the tensor shape."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX0CgxmWYFsu",
        "colab_type": "text"
      },
      "source": [
        "What can we see here?, simplifying we have:\n",
        "\n",
        "*   **tensor_1d**: Its shape tells us that it has 4 objects, and this objects doesn't have any elements (1 dimension).\n",
        "*   **tensor_2d**: Its shape tells us that it has 2 objects, and each object has 3 elements (it is 2-dimensional).\n",
        "*   **tensor_3d**: Its shape tells us that it has 2 objects, with 2 elements each and each element has 3 components (it is 3-dimensional).\n",
        "\n",
        "  We check this using ```tf.rank()``` :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_BC30vZae8L",
        "colab_type": "code",
        "outputId": "c30e5361-2950-4581-f6fe-ba3cbd300e68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(\"tensor_1d is a tensor with {} dimensions\".format(tf.rank(tensor_1d)))\n",
        "print(\"tensor_2d is a tensor with {} dimensions\".format(tf.rank(tensor_2d)))\n",
        "print(\"tensor_3d is a tensor with {} dimensions\".format(tf.rank(tensor_3d)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor_1d is a tensor with 1 dimensions\n",
            "tensor_2d is a tensor with 2 dimensions\n",
            "tensor_3d is a tensor with 3 dimensions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv9pUIS6dtsT",
        "colab_type": "text"
      },
      "source": [
        "## **Tensor operations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUnJvuL6mR8r",
        "colab_type": "text"
      },
      "source": [
        "We will try to compute this operation:\n",
        "\n",
        "![add graph image](https://github.com/theesmoxDEV/ML-AI/blob/master/Intro%20to%20TensorFlow%20%26%20Keras/add-graph.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvPKtn-MeB2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Nodes in the graph:\n",
        "a = tf.constant(1)\n",
        "b = tf.constant(2)\n",
        "\n",
        "# Addition of the nodes:\n",
        "c = tf.add(a,b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPc3wyB8egdk",
        "colab_type": "text"
      },
      "source": [
        "Lets try a more complex operation:\n",
        "\n",
        "![computation graph image](https://github.com/theesmoxDEV/ML-AI/blob/master/Intro%20to%20TensorFlow%20%26%20Keras/computation-graph.png?raw=1)\n",
        "\n",
        "We will see two approaches:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPSjMYWeenTO",
        "colab_type": "code",
        "outputId": "345a50dc-fdb4-4935-93c3-90dead93add7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "## APPROACH 1 ##\n",
        "# We simply perform the operations\n",
        "\n",
        "# Initial nodes in the graph:\n",
        "a2 = tf.constant(1) \n",
        "b2 = tf.constant(2)\n",
        "\n",
        "# Intermediate nodes:\n",
        "c2 = tf.add(a2,b2)\n",
        "d2 = tf.subtract(b2,1)\n",
        "\n",
        "# Final node:\n",
        "e2 = tf.multiply(c2,d2) # element-wise matrices multiplication\n",
        "\n",
        "print(\"Result from approach 1: {}\".format(e2))\n",
        "\n",
        "## APPROACH 2 ##\n",
        "# We define a function to compute the operation\n",
        "\n",
        "def operation(a,b): # We suppose that 'a' and 'b' are tensors\n",
        "  c,d = tf.add(a,b), tf.subtract(b,1)\n",
        "  return tf.multiply(c,d)\n",
        "\n",
        "print(\"Result from approach 2: {}\".format(operation(a2,b2)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result from approach 1: 3\n",
            "Result from approach 2: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZbSrWpplpXq",
        "colab_type": "text"
      },
      "source": [
        "We can multiply matrices using ```tf.matmul```.\n",
        "Keep in mind that shape of matrices have to be transposed.\n",
        "Here we have two different ways of calculating it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3Hu8xx2jET-",
        "colab_type": "code",
        "outputId": "1c3509db-7d77-4442-c33c-780188f0ebf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "constant1 = tf.constant([[1,2,3]], shape = (3,1))\n",
        "constant2 = tf.constant([[3,2,1]], shape = (1,3))\n",
        "print(tf.matmul(constant1, constant2))\n",
        "\n",
        "print(\"----------------------------------------\")\n",
        "\n",
        "constant3 = tf.constant([[1,2,3]])\n",
        "constant4 = tf.constant([[3,2,1]])\n",
        "print(tf.matmul(constant3, constant4, transpose_a=True))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[3 2 1]\n",
            " [6 4 2]\n",
            " [9 6 3]], shape=(3, 3), dtype=int32)\n",
            "----------------------------------------\n",
            "tf.Tensor(\n",
            "[[3 2 1]\n",
            " [6 4 2]\n",
            " [9 6 3]], shape=(3, 3), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceenrgwUdHjn",
        "colab_type": "text"
      },
      "source": [
        "# **Keras**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSFDJM9fmw6E",
        "colab_type": "text"
      },
      "source": [
        "As described in www.keras.io :\n",
        "\n",
        ">**Keras is a high-level neural networks API**, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation.\n",
        "\n",
        "But, basically, it is a **tool to build neural networks**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrEsRvRW3CvK",
        "colab_type": "text"
      },
      "source": [
        "We will use the Keras API for easy-build neural networks. It is implemented as\n",
        "```tf.keras``` (we could use it outside TensorFlow, but this is easier if we are going to use TensorFlow). Now, with TensorFlow 2.0, there are two main ways of building a \n",
        "simple neural net:\n",
        "\n",
        "*   Using ```tf.keras.Sequential``` (the \"classic\" way)\n",
        "*   Using the ***Keras functional API*** (the \"new\" way)\n",
        "\n",
        "\n",
        "> To keep in mind: The tf.keras version in the latest TensorFlow release might not be the same as the latest keras version from PyPI. Check tf.keras.version.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn0s_ZtFmfgT",
        "colab_type": "text"
      },
      "source": [
        "## **Building Neural Networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lpo3COr5kGSs",
        "colab_type": "text"
      },
      "source": [
        "### **tf.keras.Sequential**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoqqlQ2QXJfq",
        "colab_type": "text"
      },
      "source": [
        "This is the \"classic way\" of building a NN. \n",
        "We are going to build a simple fully-connected NN with 1 hidden layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4lajDl9Jnt7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "# Adds a densely-connected layer with 64 units to the model,\n",
        "# with the input data shape -> (32,)\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(32,)))\n",
        "# Add another:\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# Add an output layer with 10 output units:\n",
        "model.add(layers.Dense(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1Ok0m2QJvzu",
        "colab_type": "text"
      },
      "source": [
        "This is the same as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StcL9icQJ1ng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "# Adds a densely-connected layer with 64 units to the model,\n",
        "# with the input data shape -> (32,)\n",
        "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
        "# Add another (we don't need the input shape because it is\n",
        "# a hidden layer):\n",
        "layers.Dense(64, activation='relu'),\n",
        "# Add an output layer with 10 output units:\n",
        "layers.Dense(10)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz-n_nuZKRww",
        "colab_type": "text"
      },
      "source": [
        "The base of a NN is the model object (in this case we are using ```Sequential()```), were we add Layers and more things\n",
        "that we will see later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCjZJ_2yTWnY",
        "colab_type": "text"
      },
      "source": [
        "### **Keras functional API**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Pb2Jyo2ZPi2",
        "colab_type": "text"
      },
      "source": [
        "The Keras functional API is a (new) way to create models that are more flexible than the ```tf.keras.Sequential``` API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDzt69qAU47f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "# We create the input data , with shape -> (32,)\n",
        "inputs = keras.Input(shape=(32,))\n",
        "# We create a densely-connected layer with 64 units to the model\n",
        "dense = layers.Dense(64, activation='relu')\n",
        "# We combine the input shape and the dense layer to build our input layer\n",
        "# and store it in x\n",
        "x = dense(inputs)\n",
        "# We add another dense layer with 64 units to x\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "# We create the output layer with 10 units by adding one more layer to x\n",
        "outputs = layers.Dense(10)(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name='mnist_model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAaisLceVybq",
        "colab_type": "text"
      },
      "source": [
        "### **Compiling and training the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "852xA4zPuIeF",
        "colab_type": "text"
      },
      "source": [
        "Once we have the model (it doesn't matter which way we choose), we have to compile it. This is the moment when we specify optimizers, the loss function, etc (we will cover these things later on):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEyZU9z0OznB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.01), \n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxC12IcMO90l",
        "colab_type": "text"
      },
      "source": [
        "After compiling our model, we can train it with data. We can use either NumPy\n",
        "or a ```tf.data``` instance:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0uOoaP9u0eC",
        "colab_type": "text"
      },
      "source": [
        "#### **Using NumPy**\n",
        "\n",
        "For small datasets, use in-memory NumPy arrays to train and evaluate a model. The model is \"fit\" to the training data using the fit method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0aTj79-QFNm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "607636ea-e63b-4b4a-c0ac-14add70a8ae5"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# We load our data and our targets(labels)\n",
        "data = np.random.random((1000, 32))\n",
        "labels = np.random.random((1000, 10))\n",
        "\n",
        "# We train our model\n",
        "model.fit(data, labels, epochs=10, batch_size=32)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 0s 490us/sample - loss: 59.5002 - accuracy: 0.0920\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 0s 56us/sample - loss: 275.5033 - accuracy: 0.0950\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 0s 65us/sample - loss: 1129.5385 - accuracy: 0.1050\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 0s 59us/sample - loss: 2972.0064 - accuracy: 0.0980\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 0s 63us/sample - loss: 5992.9359 - accuracy: 0.0850\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 0s 57us/sample - loss: 8233.1830 - accuracy: 0.1050\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 0s 53us/sample - loss: 15413.0997 - accuracy: 0.1100\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 0s 69us/sample - loss: 25052.7254 - accuracy: 0.1070\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 0s 62us/sample - loss: 31888.9541 - accuracy: 0.0920\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 0s 55us/sample - loss: 34854.8478 - accuracy: 0.1050\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f08325ac1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InXWGlPFQXpX",
        "colab_type": "text"
      },
      "source": [
        "#### **Using tf.data**\n",
        "Use the Datasets API to scale to large datasets or multi-device training. Pass a tf.data.Dataset instance to the fit method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVq20p5GP73r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e0aa9a63-ff29-45b8-9459-d33f87af0677"
      },
      "source": [
        "# Instantiates a toy dataset instance:\n",
        "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
        "dataset = dataset.batch(32)\n",
        "\n",
        "model.fit(dataset, epochs=10)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 32 steps\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 31288.4033 - accuracy: 0.0920\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 58661.8913 - accuracy: 0.1000\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 57849.7765 - accuracy: 0.1040\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 77716.2611 - accuracy: 0.0940\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 98018.0269 - accuracy: 0.1210\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 82279.2210 - accuracy: 0.0990\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 93693.8182 - accuracy: 0.1030\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 112608.4682 - accuracy: 0.0890\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 104436.0405 - accuracy: 0.1210\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 163665.7566 - accuracy: 0.1090\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f08325c2668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrpBxFshIRS-",
        "colab_type": "text"
      },
      "source": [
        "### **Evaluating our model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJVZweGkIYyg",
        "colab_type": "text"
      },
      "source": [
        "Once we have our model trained, we can test its accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIP08mLeIndI",
        "colab_type": "text"
      },
      "source": [
        "#### **Using NumPy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMd8jqzOIh6e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f07e0323-03b9-4baa-a9d8-3a2cbf628317"
      },
      "source": [
        "# With Numpy arrays\n",
        "data = np.random.random((1000, 32))\n",
        "labels = np.random.random((1000, 10))\n",
        "\n",
        "model.evaluate(data, labels)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 105us/sample - loss: 163742.8680 - accuracy: 0.1140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[163742.868, 0.114]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJiH6he2IxP1",
        "colab_type": "text"
      },
      "source": [
        "#### **Using tf.data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-jFYTc5I0EG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b8872383-d08d-41bf-c363-b15b55c06dc3"
      },
      "source": [
        "# With a Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
        "dataset = dataset.batch(32)\n",
        "\n",
        "model.evaluate(dataset)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 3ms/step - loss: 163379.2178 - accuracy: 0.1140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[163379.2177734375, 0.114]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlDjiDfEJAnj",
        "colab_type": "text"
      },
      "source": [
        "### **Predicting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nn2lng1qJD0V",
        "colab_type": "text"
      },
      "source": [
        "When we are happy with our model's accuracy, we can start predicting on new data. This is as simple as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeMHzODXJKhQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "e21e1990-9d91-4206-f53f-d98ca4b9b159"
      },
      "source": [
        "result = model.predict(data)\n",
        "print(result)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[39615908. 39514750. 39607230. ... 39569630. 39604076. 39621308.]\n",
            " [39214868. 39114744. 39206292. ... 39169070. 39203160. 39220224.]\n",
            " [39445280. 39344576. 39436656. ... 39399220. 39433516. 39450670.]\n",
            " ...\n",
            " [47924936. 47802576. 47914456. ... 47868964. 47910624. 47931490.]\n",
            " [51774292. 51642092. 51762964. ... 51713824. 51758828. 51781364.]\n",
            " [40879884. 40775504. 40870936. ... 40832140. 40867676. 40885468.]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}